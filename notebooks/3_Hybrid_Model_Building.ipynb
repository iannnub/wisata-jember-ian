{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d51db6a",
   "metadata": {},
   "source": [
    "Setup & Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5afe8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 02:16:33,881 [INFO] - ✅ Library dan path siap digunakan.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # FASE 2 (V2.0): Pembangunan Model Rekomendasi Hybrid\n",
    "# \n",
    "# **Tujuan:**\n",
    "# 1. Membaca dataset bersih dan model TF-IDF dari fase sebelumnya.\n",
    "# 2. Memuat model Word2Vec (FastText) Bahasa Indonesia yang sudah di-pre-trained.\n",
    "# 3. Membuat representasi vektor untuk setiap destinasi menggunakan TF-IDF dan Word2Vec.\n",
    "# 4. Menggabungkan kedua representasi menjadi sebuah *hybrid vector*.\n",
    "# 5. Menghitung matriks kemiripan baru dari *hybrid vector* tersebut.\n",
    "# 6. Menyimpan matriks kemiripan hybrid untuk digunakan di aplikasi.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 1️⃣ SETUP & IMPORT LIBRARY\n",
    "# ======================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Konfigurasi logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] - %(message)s\")\n",
    "\n",
    "# Konfigurasi path yang robust\n",
    "# Karena notebook ini ada di dalam folder 'notebooks/', .parent akan menunjuk ke root proyek\n",
    "BASE_DIR = Path().resolve().parent \n",
    "DATA_PATH = BASE_DIR / \"data\" / \"processed\" / \"destinasi_processed.csv\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "TFIDF_VECTORIZER_PATH = MODELS_DIR / \"tfidf_vectorizer.pkl\"\n",
    "HYBRID_SIM_PATH = MODELS_DIR / \"hybrid_similarity.pkl\"\n",
    "\n",
    "logging.info(\"✅ Library dan path siap digunakan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ff7c0",
   "metadata": {},
   "source": [
    "Memuat Artefak & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cbe3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 02:16:46,293 [INFO] - ✅ Artefak TF-IDF dan dataset (55 baris) berhasil dimuat.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nama_wisata</th>\n",
       "      <th>kategori</th>\n",
       "      <th>kota</th>\n",
       "      <th>alamat</th>\n",
       "      <th>deskripsi</th>\n",
       "      <th>gambar</th>\n",
       "      <th>fitur</th>\n",
       "      <th>fitur_bersih</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Puncak Rembangan Resort</td>\n",
       "      <td>Rekreasi</td>\n",
       "      <td>Jember</td>\n",
       "      <td>Darungan, Kemuning Lor, Kec. Arjasa, Kabupaten...</td>\n",
       "      <td>Puncak Rembangan adalah destinasi wisata pegun...</td>\n",
       "      <td>assets/images/1.png</td>\n",
       "      <td>Puncak Rembangan Resort Rekreasi Rekreasi Jemb...</td>\n",
       "      <td>puncak rembangan resort rekreasi rekreasi jemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pantai Watu Ulo</td>\n",
       "      <td>Pantai</td>\n",
       "      <td>Jember</td>\n",
       "      <td>Sumberrejo, Kec. Ambulu, Kabupaten Jember, Jaw...</td>\n",
       "      <td>Pantai Watu Ulo terkenal karena batu karang pa...</td>\n",
       "      <td>assets/images/2.png</td>\n",
       "      <td>Pantai Watu Ulo Pantai Pantai Jember Sumberrej...</td>\n",
       "      <td>pantai watu ulo pantai pantai jember sumberrej...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              nama_wisata  kategori    kota  \\\n",
       "0   1  Puncak Rembangan Resort  Rekreasi  Jember   \n",
       "1   2          Pantai Watu Ulo    Pantai  Jember   \n",
       "\n",
       "                                              alamat  \\\n",
       "0  Darungan, Kemuning Lor, Kec. Arjasa, Kabupaten...   \n",
       "1  Sumberrejo, Kec. Ambulu, Kabupaten Jember, Jaw...   \n",
       "\n",
       "                                           deskripsi               gambar  \\\n",
       "0  Puncak Rembangan adalah destinasi wisata pegun...  assets/images/1.png   \n",
       "1  Pantai Watu Ulo terkenal karena batu karang pa...  assets/images/2.png   \n",
       "\n",
       "                                               fitur  \\\n",
       "0  Puncak Rembangan Resort Rekreasi Rekreasi Jemb...   \n",
       "1  Pantai Watu Ulo Pantai Pantai Jember Sumberrej...   \n",
       "\n",
       "                                        fitur_bersih  \n",
       "0  puncak rembangan resort rekreasi rekreasi jemb...  \n",
       "1  pantai watu ulo pantai pantai jember sumberrej...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Memuat Dataset dan Artefak dari Fase 1\n",
    "# \n",
    "# Kita akan memuat dataset yang sudah bersih dan TF-IDF Vectorizer yang sudah dilatih dari notebook sebelumnya.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 2️⃣ MEMUAT DATASET & TF-IDF VECTORIZER\n",
    "# ======================================================\n",
    "try:\n",
    "    with open(TFIDF_VECTORIZER_PATH, \"rb\") as f:\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    df['fitur_bersih'] = df['fitur_bersih'].fillna('') # Jaring pengaman\n",
    "    \n",
    "    logging.info(f\"✅ Artefak TF-IDF dan dataset ({len(df)} baris) berhasil dimuat.\")\n",
    "    display(df.head(2))\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"❌ File tidak ditemukan: {e}. Pastikan Anda sudah menjalankan notebook Fase 1 & 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe5852",
   "metadata": {},
   "source": [
    "Memuat Model Word2Vec (FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3dbd93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 02:16:58,635 [WARNING] - ⚠️ Model Word2Vec lokal tidak ditemukan. Memulai proses unduh (~1GB)...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Harap unduh model dari https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz dan letakkan di D:\\iann Kuliah\\Semester 7\\1. Artificial Intelegence (AI)\\wisata-recommender\\models\\fasttext_cc.id.300.vec.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     14\u001b[39m     logging.warning(\u001b[33m\"\u001b[39m\u001b[33m⚠️ Model Word2Vec lokal tidak ditemukan. Memulai proses unduh (~1GB)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Anda bisa mengunduhnya manual dan meletakkannya di folder models,\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# atau menjalankan kode ini jika koneksi internet stabil.\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# import requests\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m#             f.write(chunk)\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# logging.info(\"✅ Model Word2Vec berhasil diunduh.\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHarap unduh model dari \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW2V_DOWNLOAD_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dan letakkan di \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW2V_MODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mMemuat model Word2Vec dari penyimpanan lokal (mungkin butuh beberapa menit)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m word2vec_model = KeyedVectors.load_word2vec_format(W2V_MODEL_PATH, binary=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Harap unduh model dari https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz dan letakkan di D:\\iann Kuliah\\Semester 7\\1. Artificial Intelegence (AI)\\wisata-recommender\\models\\fasttext_cc.id.300.vec.gz"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Memuat Model Word2Vec (FastText) Bahasa Indonesia\n",
    "# \n",
    "# Kita akan menggunakan model pre-trained dari Facebook (FastText) yang sudah dilatih pada data teks Bahasa Indonesia yang sangat besar. Ini akan memberikan pemahaman semantik yang mendalam pada model kita.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 3️⃣ MEMUAT WORD2VEC (FASTTEXT)\n",
    "# ======================================================\n",
    "W2V_MODEL_PATH = MODELS_DIR / \"fasttext_cc.id.300.vec.gz\" # Path lokal untuk menyimpan model\n",
    "W2V_DOWNLOAD_URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\"\n",
    "\n",
    "if not W2V_MODEL_PATH.exists():\n",
    "    logging.warning(\"⚠️ Model Word2Vec lokal tidak ditemukan. Memulai proses unduh (~1GB)...\")\n",
    "    # Anda bisa mengunduhnya manual dan meletakkannya di folder models,\n",
    "    # atau menjalankan kode ini jika koneksi internet stabil.\n",
    "    # import requests\n",
    "    # with requests.get(W2V_DOWNLOAD_URL, stream=True) as r:\n",
    "    #     r.raise_for_status()\n",
    "    #     with open(W2V_MODEL_PATH, 'wb') as f:\n",
    "    #         for chunk in r.iter_content(chunk_size=8192):\n",
    "    #             f.write(chunk)\n",
    "    # logging.info(\"✅ Model Word2Vec berhasil diunduh.\")\n",
    "    raise FileNotFoundError(f\"Harap unduh model dari {W2V_DOWNLOAD_URL} dan letakkan di {W2V_MODEL_PATH}\")\n",
    "\n",
    "logging.info(\"Memuat model Word2Vec dari penyimpanan lokal (mungkin butuh beberapa menit)...\")\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(W2V_MODEL_PATH, binary=False)\n",
    "logging.info(\"✅ Model Word2Vec berhasil dimuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f76f09",
   "metadata": {},
   "source": [
    "Membuat Vektor Rata-rata Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150725b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Membuat Vektor Rata-rata Word2Vec untuk Setiap Destinasi\n",
    "# \n",
    "# Kita akan mengubah setiap teks 'fitur_bersih' menjadi satu vektor tunggal dengan cara merata-ratakan vektor dari semua kata yang ada di dalamnya.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 4️⃣ MEMBUAT VEKTOR WORD2VEC PER DOKUMEN\n",
    "# ======================================================\n",
    "def get_sentence_vector(sentence, model, dimensions=300):\n",
    "    \"\"\"Mengubah sebuah kalimat menjadi vektor rata-rata dari kata-katanya.\"\"\"\n",
    "    words = [word for word in sentence.split() if word in model.key_to_index]\n",
    "    if not words:\n",
    "        return np.zeros(dimensions)\n",
    "    return np.mean(model[words], axis=0)\n",
    "\n",
    "# Terapkan fungsi ke setiap baris di DataFrame\n",
    "tqdm.pandas(desc=\"Membuat vektor Word2Vec\")\n",
    "word2vec_matrix = np.array(df['fitur_bersih'].progress_apply(\n",
    "    lambda x: get_sentence_vector(x, word2vec_model)\n",
    ").tolist())\n",
    "\n",
    "logging.info(f\"✅ Matriks Word2Vec berhasil dibuat dengan ukuran: {word2vec_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16598c1b",
   "metadata": {},
   "source": [
    "Menggabungkan Vektor & Menghitung Kemiripan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Membuat Vektor Hybrid dan Menghitung Cosine Similarity\n",
    "# \n",
    "# Ini adalah inti dari V2.0. Kita akan menggabungkan kekuatan TF-IDF (yang bagus untuk kata kunci) dan Word2Vec (yang bagus untuk makna) menjadi satu vektor hybrid.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 5️⃣ MEMBUAT VEKTOR HYBRID & MENGHITUNG KEMIRIPAN\n",
    "# ======================================================\n",
    "# 1. Buat matriks TF-IDF dari data yang sama\n",
    "# ⭐ PERBAIKAN KRITIS: Gunakan 'fitur_bersih', bukan 'deskripsi'\n",
    "logging.info(\"Membuat matriks TF-IDF...\")\n",
    "tfidf_matrix = tfidf_vectorizer.transform(df['fitur_bersih']).toarray()\n",
    "\n",
    "# 2. Normalisasi kedua matriks agar skalanya seimbang\n",
    "logging.info(\"Normalisasi matriks TF-IDF dan Word2Vec...\")\n",
    "tfidf_matrix = normalize(tfidf_matrix)\n",
    "word2vec_matrix = normalize(word2vec_matrix)\n",
    "\n",
    "# 3. Gabungkan kedua matriks dengan bobot (alpha)\n",
    "alpha = 0.6  # Beri bobot lebih pada TF-IDF (kata kunci)\n",
    "hybrid_matrix = (alpha * tfidf_matrix) + ((1 - alpha) * word2vec_matrix)\n",
    "logging.info(f\"✅ Matriks Hybrid berhasil dibuat dengan bobot alpha={alpha}\")\n",
    "\n",
    "# 4. Hitung matriks cosine similarity dari vektor hybrid\n",
    "hybrid_similarity_matrix = cosine_similarity(hybrid_matrix)\n",
    "logging.info(f\"✅ Matriks kemiripan hybrid berhasil dihitung dengan ukuran: {hybrid_similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabc906",
   "metadata": {},
   "source": [
    "Menyimpan dan Menguji Model Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1136c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Menyimpan Matriks Kemiripan Hybrid\n",
    "# \n",
    "# Simpan matriks baru ini agar bisa digunakan oleh `recommender.py` dan `app.py`.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 6️⃣ MENYIMPAN MATRIKS HYBRID\n",
    "# ======================================================\n",
    "with open(HYBRID_SIM_PATH, \"wb\") as f:\n",
    "    pickle.dump(hybrid_similarity_matrix, f)\n",
    "logging.info(f\"💾 Matriks kemiripan hybrid berhasil disimpan di: {HYBRID_SIM_PATH}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Pengujian Cepat\n",
    "# \n",
    "# Mari kita lihat apakah model hybrid memberikan rekomendasi yang berbeda atau lebih baik dari model TF-IDF murni.\n",
    "\n",
    "# %%\n",
    "# ======================================================\n",
    "# 7️⃣ PENGUJIAN CEPAT\n",
    "# ======================================================\n",
    "# Pilih destinasi referensi\n",
    "nama_wisata_ref = \"Pantai Papuma\"\n",
    "\n",
    "# Dapatkan indeksnya\n",
    "idx_ref = df[df['nama_wisata'] == nama_wisata_ref].index[0]\n",
    "\n",
    "# Ambil skor kemiripan dan urutkan\n",
    "sim_scores = list(enumerate(hybrid_similarity_matrix[idx_ref]))\n",
    "sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]\n",
    "\n",
    "print(f\"\\n🎯 5 Rekomendasi Hybrid untuk '{nama_wisata_ref}':\\n\")\n",
    "for i, score in sim_scores:\n",
    "    print(f\"- {df.iloc[i]['nama_wisata']} (Skor: {score:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
