"""
======================================================
scripts/generate_embeddings.py
======================================================
MEMBUAT "OTAK" SEMANTIK V3.0

Tugas:
1. Memuat data yang sudah bersih dari 'data/processed/'.
2. Memuat model SentenceTransformer (dioptimalkan untuk kemiripan).
3. Mengubah 'fitur_bersih' dari setiap destinasi menjadi vektor embedding.
4. Menyimpan array embeddings ke 'models/bert_embeddings.pkl'.
======================================================
"""

import pandas as pd
import pickle
import logging
import time
from pathlib import Path
import sys

# Tambahkan path root proyek agar bisa impor 'src.utils'
BASE_DIR = Path(__file__).resolve().parent.parent
if str(BASE_DIR) not in sys.path:
    sys.path.append(str(BASE_DIR))

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("="*50)
    print("ERROR: Library 'sentence-transformers' belum terinstal.")
    print("Silakan jalankan: pip install sentence-transformers")
    print("="*50)
    sys.exit(1)

# Mengimpor helper dari utils
from src.utils import save_pickle

# ===============================================
# 1Ô∏è‚É£ Konfigurasi Path & Logging
# ===============================================
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] - %(message)s")

# ‚≠ê PERBAIKAN: Gunakan data yang sudah diproses
DATA_PATH = BASE_DIR / "data" / "processed" / "destinasi_processed.csv"
# ‚≠ê PERBAIKAN: Simpan model di folder 'models'
OUTPUT_PATH = BASE_DIR / "models" / "bert_embeddings.pkl"

# ‚≠ê PERBAIKAN: Gunakan model yang dioptimalkan untuk Sentence Similarity
MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'
# (Model ini akan diunduh otomatis ~471MB saat pertama kali dijalankan)

# ===============================================
# 2Ô∏è‚É£ Load Dataset Bersih
# ===============================================
logging.info(f"üì¶ Memuat dataset bersih dari: {DATA_PATH.name}")
try:
    df = pd.read_csv(DATA_PATH)
except FileNotFoundError:
    logging.error(f"‚ùå File tidak ditemukan di {DATA_PATH}.")
    logging.error("Pastikan Anda sudah menjalankan notebook '1_Data_Exploration.ipynb' terlebih dahulu.")
    sys.exit(1)

# Pastikan kolom 'fitur_bersih' ada dan tidak kosong
if "fitur_bersih" not in df.columns:
    raise ValueError("‚ùå Kolom 'fitur_bersih' tidak ditemukan di dataset!")
df['fitur_bersih'] = df['fitur_bersih'].fillna('')
logging.info(f"‚úÖ Dataset berhasil dimuat. Jumlah data: {len(df)}")

# ===============================================
# 3Ô∏è‚É£ Load Model SentenceTransformer
# ===============================================
logging.info(f"ü§ñ Memuat model SentenceTransformer: '{MODEL_NAME}'...")
try:
    start_time = time.time()
    model = SentenceTransformer(MODEL_NAME)
    logging.info(f"‚úÖ Model berhasil dimuat dalam {time.time() - start_time:.2f} detik")
except Exception as e:
    logging.error(f"‚ùå Gagal mengunduh/memuat model: {e}")
    logging.error("Pastikan Anda memiliki koneksi internet untuk mengunduh model.")
    sys.exit(1)

# ===============================================
# 4Ô∏è‚É£ Generate Embeddings
# ===============================================
logging.info("üß† Mengonversi 'fitur_bersih' menjadi vektor embeddings...")

# ‚≠ê PERBAIKAN: Gunakan 'fitur_bersih' untuk mendapatkan makna semantik terkaya
corpus = df["fitur_bersih"].astype(str).tolist()

embeddings = model.encode(
    corpus,
    show_progress_bar=True,
    convert_to_numpy=True
)
logging.info(f"‚úÖ Embedding selesai. Shape: {embeddings.shape}")

# ===============================================
# 5Ô∏è‚É£ Simpan Embeddings (Hanya Vektornya)
# ===============================================
# ‚≠ê PERBAIKAN: Kita hanya perlu menyimpan array numpy-nya.
# Data 'nama_wisata' akan kita dapatkan dari file CSV di recommender.py
save_pickle(embeddings, OUTPUT_PATH)
logging.info("üéâ Proses selesai ‚Äî Embeddings V3.0 siap digunakan!")